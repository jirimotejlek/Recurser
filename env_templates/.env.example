# Copy this file to .env and fill in your values
# DO NOT commit .env to version control!

# ========================================
# LLM Provider Configuration
# ========================================

# Provider name (e.g., openai, anthropic, mistral, cohere, custom)
LLM_PROVIDER=openai

# API Key for your chosen provider
LLM_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxx

# API Endpoint
# Examples for different providers:
# OpenAI: https://api.openai.com/v1
# Anthropic: https://api.anthropic.com/v1
# Mistral: https://api.mistral.ai/v1
# Cohere: https://api.cohere.ai/v1
# Custom/Local: http://your-server:8080/v1
LLM_API_ENDPOINT=https://api.openai.com/v1

# Model to use (provider-specific)
# OpenAI: gpt-4, gpt-3.5-turbo
# Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229
# Mistral: mistral-large-latest, mistral-medium-latest
# Cohere: command, command-light
LLM_MODEL=gpt-4

# Optional: Additional configuration
# Some providers need extra headers or API version
# LLM_API_HEADERS={"X-Custom-Header": "value"}
# LLM_API_VERSION=2024-02-01

# ========================================
# Other Configuration
# ========================================

# Optional: Optimizer API key (if you want to change the default)
# OPTIMIZER_KEY=your-secret-optimizer-key